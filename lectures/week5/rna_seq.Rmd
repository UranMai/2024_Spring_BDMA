---
title: "An Introduction to RNA-sequencing"
subtitle: "GSND 5340Q, BMDA"
author: | 
  | W. Evan Johnson, Ph.D.
  | Professor, Division of Infectious Disease
  | Director, Center for Data Science
  | Rutgers University -- New Jersey Medical School
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{amsmath}
output: 
  beamer_presentation:
    theme: "CambridgeUS"
editor_options: 
  chunk_output_type: console
tables: true
---


## Installing R Packages: 

Install the following tools: `Rsubread`, `Rsamtools`,  `edgeR`, `DESeq2`, `sva` `SummarizedExperiment`, `ComplexHeatmap`, `umap`, and the `TBSignatureProfiler`. We will also need help from the `tidyverse.`

```{r eval=F}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install(c("Rsubread","Rsamtools","tidyverse",
  "SummarizedExperiment","edgeR","DESeq2","sva","ComplexHeatmap",
  "TBSignatureProfiler","umap"))
```

## Installing and using the SCTK

```{r, eval=F}
install.packages("devtools")
devtools::install_github("wevanjohnson/singleCellTK")
library(singleCellTK)
singleCellTK()

### Example: open downstream_analysis/ 
### features_combined.txt and meta_data.txt
```


## Load Packages for RNA-Seq
We will be using the following packages for our RNA-seq lecture:
```{r, warning=FALSE, message=FALSE}
library(tidyverse) ## tools for data wranging
library(Rsubread) ## alignment and feature counts
library(Rsamtools) ## managing .sam and .bam files
library(SummarizedExperiment) ## managing counts data
library(edgeR) ## differential expression
library(DESeq2) ## differential expression
library(ComplexHeatmap) ## Heatmap visualization
library(TBSignatureProfiler) ## TB signature analysis
library(umap) ## dimenstion reduction and plotting data
```

## Objective

\Large
* Disclaimer: non-comprehensive introduction to RNA-sequencing 
* Introduce preprocessing steps
* Visualization 
* Analytical methods 
* Common software tools

## Steps to an RNA-seq Analysis (Literacy)

\Large
1. Preprocessing and QC:
    + Fasta and Fastq files
    + FastQC: good vs. bad examples
    + Visualization
2. Alignment
    + Obtaining genome sequence and annotation
    + Software: Bowtie, TopHat, STAR, Subread/Rsubread
3. Expression Quantification
    + Count reads hitting genes, etc
    + Approaches/software: HT-Seq, STAR, Cufflinks, RPKM FPKM or CPM, RSEM, edgeR, findOverlaps (GenomicRanges). featureCounts (Rsubread)

## Steps to an RNA-seq Analysis (Literacy)

\Large
4. More visualization
    + Heatmaps, boxplots, PCA, t-SNE, UMAP
5. Differential Expression
    + Batch correction
    + Overdispersion
    + General Workflow
    + Available tools: edgeR, DESeq, Limma/voom
    + Even more visualization!!

## Illumina Sequencing Workflow

\center
![](rna_seq/figs/illumina.png){height=85%}

## Sequencing Data Formats {.tabset}

Genome sequcencing data is often stored in one of two formats, FASTA and FASTQ text files. For example a FASTA files looks like the following: 

![](rna_seq/figs/fasta.png)

## FASTQ Files
We can also store confidence or quality scores using a FASTQ format: 
![](rna_seq/figs/fastq.png)

## FASTQ Encoding
In order to translate FASTQ quality scores: 

![](rna_seq/figs/encoding1.png)

## FASTQ Probability
And now converting to confidence probabilities: 

![](rna_seq/figs/encoding2.png)

## Preprocessing and QC using FASTQC
\Large 
[FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) provides a simple way to do QC checks on raw sequence data:  

* Import of data from BAM, SAM or FastQ files
* Quick overview and summary graphs and tables to quickly assess your data
* Export of results to an HTML based permanent report
* Offline operation to allow automated generation of reports without running the interactive application

## Preprocessing and QC using FASTQC

\Large 
To run FastQC you can launch the GUI app, or run form the command line: 

```{bash, eval=F}
rna_seq/FastQC/./fastqc \
  rna_seq/reads/R01_10_short500K.fq.gz
```

## FastQC Score Distribution
![](rna_seq/figs/fastqcscore.png){width=49%}
![](rna_seq/figs/fastqcscoredist.png){width=49%}


## FastQC Base and N Distribution
![](rna_seq/figs/fastqcbase.png){width=49%}
![](rna_seq/figs/fastqcn.png){width=49%}

## Alignment to the Reference Genome
**Goal**: Find the genomic Location of origin for the sequencing read. Software: `Bowtie2`, `TopHat`, `STAR`, `Subread/Rsubread`, many others!

![](rna_seq/figs/align1.png)

### Using Rsubread to do Alignment

\Large 
The following userguide will be helpful for you: 

http://bioinf.wehi.edu.au/subread-package/SubreadUsersGuide.pdf


## Indexing your genome

\Large 

> Abraham Lincoln: "Give me six hours to chop down a tree and I will spend the first four sharpening the axe." (4 minutes indexing the genome, 2 minutes aligning the reads)

## Indexing your genome

\large 
Note that you will rarely do this for human alignment. You will usually download an existing index given to you by others who have already done this work. You will do this often if you are aligning microbial reads, e.g. MTB or some other organism for which others have not already made your index for you.

\normalsize
```{r, eval=F}
buildindex(basename="rna_seq/genome/ucsc.hg19.chr1_120-150M",
 reference="rna_seq/genome/ucsc.hg19.chr1_120-150M.fasta.gz")
```

\large
Took me ~0.2 minutes!

## Aligning your reads:  
Note that this outputs results in a .bam file and not a .sam file

```{r, eval=F, include=F}
align(index="rna_seq/genome/ucsc.hg19.chr1_120-150M",readfile1="rna_seq/reads/R01_10_short6M.fq.gz",output_file="rna_seq/alignments/R01_10_short.bam", nthreads=4)
```

```{r eval=F, include=F}
align(index="rna_seq/genome/ucsc.hg19.chr1_120-150M",readfile1="rna_seq/reads/R01_10_short500K.fq.gz",output_file="rna_seq/alignments/R01_10_short.bam", nthreads=4) 
```

```{r, eval=F}
align(index="rna_seq/genome/ucsc.hg19.chr1_120-150M",
      readfile1="rna_seq/reads/R01_10_short500K.fq.gz",
      output_file="rna_seq/alignments/R01_10_short.bam", 
      nthreads=4) 
```

My laptop is an Apple M2, which has 8 cores (used 4 cores), 24GB RAM: 

  - Took 15.7 minutes to align ~60M reads to the 30M bases
  - Took 0.7 minutes to align ~6.5M reads to the 30M bases
  - Took 0.3 minutes to align ~500K reads to the 30M bases

## Aligned Sequencing Data Formats (SAM and BAM)
Note that Rsubread outputs a .bam file (bam = binary alignment map) and not a .sam file (sam = sequence alignment map). Here is some information about a .sam file: https://en.wikipedia.org/wiki/SAM_(file_format)

![](rna_seq/figs/sambam.png)

## Aligned Sequencing Data Formats (SAM and BAM)
To convert .sam to .bam or vice versa, a package called Rsamtools. Using Rsamtools, you can convert bam to sam as follows:

```{r, eval=F}
asSam("rna_seq/alignments/R01_10_short.bam", 
      overwrite=T) 

# To convert to bam:
#asBam("rna_seq/alignments/R01_10_short.bam") 
```


## Feature counts
\Large
Now we can count reads hitting genes. Approaches/software: 

* HT-Seq
* STAR
* Cufflinks
* RPKM FPKM or CPM
* RSEM
* edgeR
* findOverlaps (GenomicRanges)
* featureCounts (Rsubread)

## Feature counts
\center
![](rna_seq/figs/featurecounts.png){height=85%}

## Feature counts

```{r, eval=FALSE}
fCountsList = featureCounts(
  "rna_seq/alignments/R01_10_short.bam",
  annot.ext="rna_seq_files/genome/genes.chr1_120-150M.gtf",
  isGTFAnnotationFile=TRUE)

featureCounts = cbind(fCountsList$annotation[,1], 
                      fCountsList$counts)

write.table(featureCounts, 
    "rna_seq/alignments/R01_10_short.features.txt", 
    sep="\t", col.names=FALSE, row.names=FALSE, quote=FALSE)
```


## SCTK
\Large
Use the Single Cell Toolkit (SCTK) to analyze your RNA-seq data!

* Inputs: RNA-seq, Nanostring, Proteomic, immunological assay data
* Interactive analyses and visualization of data
* Save results, figures, etc
* Sophisticated data structures
* R/Bioconductor package

## SCTK
![](rna_seq/figs/sctk1.png)

## SCTK
![](rna_seq/figs/sctk2.png)

## Installing and using the SCTK

```{r, eval=F}
install.packages("devtools")
devtools::install_github("wevanjohnson/singleCellTK")
library(singleCellTK)
singleCellTK()

### Example: open downstream_analysis/ 
### features_combined.txt and meta_data.txt
```

## Batch effects 
\Large
>Batch Effect: Non-biological variation due to differences in batches of data that confound the relationships between covariates of interest. 

Batch effects are caused by differences in:

* Gene expression profiling platform
* Lab protocol or experimenter
* Time of day or processing
* Atmospheric ozone level (Rhodes et al. 2004)

## Batch Effect Example #1: Nirtic Oxide
Example 1 resulted from an oligonucleotide microarray (Affymetrix HG-U133A) experiment on human lung fibroblast cells (IMR90) designed to reveal whether exposing mammalian cells to nitric oxide (NO) stabilizes mRNAs. Control samples and samples exposed to NO for 1 h were then transcription inhibited for 7.5 h. 

Microarray data were collected at baseline (0 h, just before transcription inhibition) and at the end of the experiment (after 7.5 h) for both the control and the NO-treated group. It was hypothesized that NO will induce or inhibit the expression of some genes, but would also stabilize the mRNA of many genes, preventing them from being degraded after 7.5 h. 

## Batch Effect Example #1: Nirtic Oxide
![](rna_seq/figs/batch1.png)

## Batch Effect Example #2: Control Gene Expression
![Figure 15](rna_seq/figs/batch2.png){height=90%}

#### Batch Effect Example #3: Proteomic markers
**Proteomic markers to predict endometriosis (39 total)**:

\Large
Single peptide predictors of disease (AUC): 0.82, 0.76, 0.74, 0.74, 0.70 (+12 more >0.6)

Single peptide predictors of batch (AUC): 0.99, 0.94, 0.91, 0.86, 0.86, 0.84, 0.84, 0.84, 0.83, 0.82 (+7 more >0.6)

Predict batch better than disease!

## ComBat Batch Adjustment
![](rna_seq/figs/batchmodel.png)

## ComBat Batch Adjustment
![](rna_seq/figs/batchadjust.png)

## Normalization
\Large
Need to normalize data because of:

* Sequencing depth difference in each RNA sample
* RNA composition differences
* Highly expressed genes can consume a substantial proportion of RNA-Seq reads, causing other genes to be under-sampled
* Different methods
    + Log counts
    + Counts per million (CPM and logCPM; RPKM, FPKM)
    + Trimmed mean of M-values (edgeR/limma)
    + Median of Ratios method (DESeq)

## Normalization   
![](rna_seq/figs/norm1.png)

## Problem of overdispersion: 
Alignment and feature counting result in discrete count data (i.e. the number of reads to each gene). A first thought might be to use a Poisson distribution to model the counts. However, the Poisson makes a strict mean-variance assumption (i.e. they are the same. Studies have demonstrated that a negative binomial fits data better. 

## Problem of overdispersion: 
![](rna_seq/figs/overdisperse.png)

## Data Structures
\Large
A data structure is a particular way of organizing data in a computer so that it can be used effectively. The idea is to reduce the space and time complexities of different tasks.

## Data Structures
\Large
Data structures in R programming are tools for holding multiple values, variables, and sometimes functions

**Please think very carefully about the way you manage and store your data!** This can make your life much easier and make your code and data cleaner and more portable!

## Data Structures
\Large
There are advanced R data structures, __S3__ and __S4__ class objects, that can facilitate object orientated programming. One useful example of an S4 class data structure is the __SummarizedExperiment__ object. 

## Data Structures
\Large
![](rna_seq/figs/summarizedexperiment.png)


## Visualization and Dimension reduction

Using an example dataset from: [Verma, et al., 2018](https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-018-3127-4)
```{r}
## read in data
counts <- read.table(
  "rna_seq/downstream_analysis/features_combined.txt", 
  sep="\t", header=T, row.names=1)
meta_data <- read.table(
  "rna_seq/downstream_analysis/meta_data.txt",
  sep="\t", header=T, row.names=1)
group <- meta_data$Disease
```

## Visualization and Dimension reduction
```{r}
## Make SummarizedExperiemnt
sce_hivtb <- SummarizedExperiment(assays=list(counts=counts),
                     colData = meta_data)

## Make log counts, counts per million (cpm), logcpm
sce_hivtb <- mkAssay(sce_hivtb, log = TRUE, 
                     counts_to_CPM = TRUE)
assays(sce_hivtb)
```

## Principal Components Analysis (PCA)

```{r, eval=F}
set.seed(1)
pca_out <- prcomp(t(assay(sce_hivtb,"log_counts_cpm")))
  
pca_plot <- as.data.frame(pca_out$x)
pca_plot$Disease <- as.factor(sce_hivtb$Disease)

g <- pca_plot %>% ggplot(aes(x=PC1, y=PC2, color=Disease)) +
  geom_point(size=1.5) + xlab("PCA1") + ylab("PCA2") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle("PCA Plot")

plot(g)
```

## Principal Components Analysis (PCA)

```{r, echo=F, fig.height=4, fig.align='center'}
set.seed(1)
pca_out <- prcomp(t(assay(sce_hivtb,"log_counts_cpm")))
  
pca_plot <- as.data.frame(pca_out$x)
pca_plot$Disease <- as.factor(sce_hivtb$Disease)

g <- pca_plot %>% ggplot(aes(x=PC1, y=PC2, color=Disease)) +
  geom_point(size=1.5) + xlab("PCA1") + ylab("PCA2") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle("PCA Plot")

plot(g)
```


## Uniform Manifold Approximation and Projection (UMAP)
\Large
For more on UMAP, please visit the following excellent tutorial: 
https://pair-code.github.io/understanding-umap/

## Uniform Manifold Approximation and Projection (UMAP)

```{r, eval=F}
set.seed(1)
umap_out <- umap(t(assay(sce_hivtb,"log_counts_cpm")))

umap_plot <- as.data.frame(umap_out$layout)
umap_plot$Disease <- as.factor(sce_hivtb$Disease)

g <- umap_plot %>% ggplot(aes(x=V1, y=V2, color=Disease)) +
  geom_point(size=1.5) + xlab("UMAP1") + ylab("UMAP2") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle("UMAP Plot")

plot(g)
```


## Uniform Manifold Approximation and Projection (UMAP)

```{r, echo=F,fig.height=4, fig.align='center'}
set.seed(1)
umap_out <- umap(t(assay(sce_hivtb,"log_counts_cpm")))

umap_plot <- as.data.frame(umap_out$layout)
umap_plot$Disease <- as.factor(sce_hivtb$Disease)

g <- umap_plot %>% ggplot(aes(x=V1, y=V2, color=Disease)) +
  geom_point(size=1.5) + xlab("UMAP1") + ylab("UMAP2") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle("UMAP Plot")

plot(g)
```


## Differential Expression {.tabset}

![](rna_seq/figs/difex.png)

## EdgeR Example
Implements statistical methods for DE analysis based on the negative binomial model:

```{r}
#Gene Filtering
counts<-counts[which(rowSums(cpm(counts))>1),] 
#Computes library size
dge <- DGEList(counts=counts, group=group) 
#TMM normalization
dge <- calcNormFactors(dge) 
# Design matrix
design<-model.matrix(~group)
#Estimates common, trended and tagwise dispersion
dge<-estimateDisp(counts,design) 
```

## EdgeR Example
In negative binomial models, each gene is given a dispersion parameter.  Dispersions control the variances of the gene counts and underestimation will lead to false discovery and overestimation may lead to a lower rate of true discovery

## EdgeR Example
```{r}
## Performs likelihood ratio tests
#fits a negative binomial GLM with the dispersion estimates
fit<-glmFit(counts,design, dispersion=dge$tagwise.dispersion) 
# Performs likelihood ratio test
# Compares the goodness of the fit, full versus reduced model
lrt<-glmLRT(fit, coef=2) 
# Prints the top results
topTags(lrt)
```

## EdgeR Example
```{r}
# Perform quasi-likelihood F-tests
## Replace the chisquare approximation to the likelihood 
## ratio statistic with a quasi-likelihood F-test, 
## more control of error rate
fit<-glmQLFit(counts, design, 
        dispersion=dge$tagwise.dispersion) 
## use for small dataset, reflects uncertainty in estimating 
## control when the number of replicates is small dispersion 
## for each gene, more robust and reliable error rate 
qlf<-glmQLFTest(fit, coef=2)
topTags(qlf)
```

## EdgeR Example
```{r}
#For visualization, heatmaps/PCA
Logcpm<-cpm(counts,log=TRUE)
```

